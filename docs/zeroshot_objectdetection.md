# ğŸ“– Solution

## What is Zero-Shot Object Detection?

Zero-Shot Object Detection(ZSOD)ì€ ì‚¬ì „ í•™ìŠµëœ í´ë˜ìŠ¤(label)ë¿ë§Œ ì•„ë‹ˆë¼ **ìƒˆë¡œìš´ ê°ì²´ë¥¼ í…ìŠ¤íŠ¸ ì¿¼ë¦¬ ê¸°ë°˜ìœ¼ë¡œ íƒì§€í•  ìˆ˜ ìˆëŠ” AI ê¸°ìˆ **ì…ë‹ˆë‹¤. ê¸°ì¡´ ê°ì²´ íƒì§€ ëª¨ë¸(YOLO, Faster R-CNN ë“±)ì€ ë¯¸ë¦¬ í•™ìŠµëœ í´ë˜ìŠ¤ë§Œ íƒì§€í•  ìˆ˜ ìˆëŠ” ë°˜ë©´, ZSODëŠ” ìì—°ì–´ ê¸°ë°˜ì˜ ì…ë ¥ì„ í™œìš©í•˜ì—¬ **ì´ì „ì— í•™ìŠµëœ ì  ì—†ëŠ” ê°ì²´ë„ íƒì§€ ê°€ëŠ¥**í•©ë‹ˆë‹¤. ë³¸ ì†”ë£¨ì…˜ì€ **Grounding DINO** ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ë©°, mellerikat MLOps í”„ë ˆì„ì›Œí¬(ALO)ì— ìµœì í™”ëœ í˜•íƒœë¡œ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤.

## When to use Zero-Shot Object Detection?

Zero-Shot Object Detectionì€ ë‹¤ìŒê³¼ ê°™ì€ ë¶„ì•¼ì—ì„œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

- **ì‚°ì—… ìë™í™” ë° ê³µì • ê´€ë¦¬**: ìƒˆë¡œìš´ ë¶€í’ˆì´ë‚˜ ë¶ˆëŸ‰ ìœ í˜•ì´ ë°œìƒí–ˆì„ ë•Œ, í•™ìŠµ ì—†ì´ë„ ì¦‰ì‹œ íƒì§€ ê°€ëŠ¥
- **ììœ¨ ì£¼í–‰ ë° ìŠ¤ë§ˆíŠ¸ ëª¨ë‹ˆí„°ë§**: íŠ¹ì • ìƒí™©ì´ë‚˜ ëŒ€ìƒ(ì˜ˆ: "red car" ë˜ëŠ” "pedestrian with blue backpack")ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ íƒì§€ ê°€ëŠ¥
- **ë³´ì•ˆ ë° ê°ì‹œ ì‹œìŠ¤í…œ**: ê¸°ì¡´ í•™ìŠµëœ ê°ì²´ ì™¸ì—ë„ "ìœ„í—˜í•œ ë¬¼ì²´" ë˜ëŠ” "ìˆ˜ìƒí•œ í–‰ë™ì„ í•˜ëŠ” ì‚¬ëŒ"ê³¼ ê°™ì€ ê°œë…ì„ íƒì§€ ê°€ëŠ¥
- **ì˜ë£Œ ì˜ìƒ ë¶„ì„**: ë¯¸ë¦¬ ì •ì˜ë˜ì§€ ì•Šì€ ë³‘ë³€ì´ë‚˜ íŠ¹ì • ì¡°ì§ íŒ¨í„´ì„ í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ íƒìƒ‰ ê°€ëŠ¥

## Key Features and Benefits

Zero-Shot Object Detectionì€ **ì‚¬ì „ í•™ìŠµëœ í´ë˜ìŠ¤ ì—†ì´ë„** ê°ì²´ë¥¼ íƒì§€í•  ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

- **Open-Vocabulary Detection**: "ìƒˆë¡œìš´ í´ë˜ìŠ¤(class)"ë¥¼ ì¶”ê°€ í•™ìŠµ ì—†ì´ë„ ì¦‰ì‹œ íƒì§€ ê°€ëŠ¥
- **í…ìŠ¤íŠ¸ ê¸°ë°˜ íƒì§€(Text-to-Detect)**: "red car", "person with a hat" ë“±ì˜ **í…ìŠ¤íŠ¸ ì¿¼ë¦¬**ë¥¼ í™œìš©í•˜ì—¬ ê°ì²´ë¥¼ íƒì§€ ê°€ëŠ¥
- **ì¦‰ê°ì ì¸ ì ìš©(Zero-Shot Adaptability)**: ìƒˆë¡œìš´ ë°ì´í„°ì…‹ì´ë‚˜ í™˜ê²½ ë³€í™”ì—ë„ ë³„ë„ì˜ í•™ìŠµ ì—†ì´ íƒì§€ ê°€ëŠ¥
- **ì‹¤ì‹œê°„ ëŒ€ì‘ ë° ìµœì í™”**: ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„°ì—ì„œë„ ë™ì‘ ê°€ëŠ¥í•˜ë©°, ì‚°ì—… ìë™í™” ë° ë³´ì•ˆ ì‹œìŠ¤í…œì—ì„œ í™œìš© ê°€ëŠ¥

# ğŸ’¡ Features

## Pipeline

Zero-Shot Object Detectionì˜ pipelineì€ **ê¸°ëŠ¥ ë‹¨ìœ„(asset)ì˜ ì¡°í•©**ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.

**Train pipeline**
```
Train
```

**Inference pipeline**
```
Inference
```

## Assets

ê° ë‹¨ê³„ëŠ” assetìœ¼ë¡œ êµ¬ë¶„ë©ë‹ˆë‹¤.

**Train asset**

Train assetì—ì„œëŠ” Grounding DINOë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. í•™ìŠµ ê³¼ì •ì—ì„œëŠ” CLIP ê¸°ë°˜ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìœµí•© ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ê°ì²´ íƒì§€ ì„±ëŠ¥ì„ ìµœì í™”í•©ë‹ˆë‹¤. ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ë©°, í•„ìš” ì‹œ ì¶”ê°€ í•™ìŠµì„ í†µí•´ ì„±ëŠ¥ì„ í–¥ìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìµœì í™”ëœ ê°€ì¤‘ì¹˜ëŠ” `model_best.pth`ë¡œ ì €ì¥ë©ë‹ˆë‹¤.

**Inference asset**

Inference assetì—ì„œëŠ” í•™ìŠµëœ ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ **Zero-Shot Object Detection**ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì…ë ¥ëœ ì´ë¯¸ì§€ì™€ ìì—°ì–´ í…ìŠ¤íŠ¸ ì¿¼ë¦¬ë¥¼ ì¡°í•©í•˜ì—¬ ê°ì²´ë¥¼ íƒì§€í•˜ê³ , íƒì§€ ê²°ê³¼ë¥¼ `predictions.csv` íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

## Experimental_plan.yaml

ë³¸ ì†”ë£¨ì…˜ì„ í™œìš©í•˜ë ¤ë©´ ì‹¤í—˜ ê³„íš íŒŒì¼(`experimental_plan.yaml`)ì„ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤. í•´ë‹¹ íŒŒì¼ì—ëŠ” ë°ì´í„° ê²½ë¡œ ë° ì‚¬ìš©ì ì •ì˜ ì¸ì(user arguments) ê°’ì´ í¬í•¨ë©ë‹ˆë‹¤.

### ë°ì´í„° ê²½ë¡œ ì„¤ì • (external_path)
```
external_path:
    - load_train_data_path: ./solution/sample_data/train/
    - load_inference_data_path: ./solution/sample_data/test/
    - save_train_artifacts_path:
    - save_inference_artifacts_path:
```

### ì‚¬ìš©ì íŒŒë¼ë¯¸í„° ì„¤ì • (user_parameters)
```
user_parameters:
    - train_pipeline:
      - step: train
        args:
          - batch_size: 16
            train_epoch: 10
            learning_rate: 0.0001
    - inference_pipeline:
      - step: inference
        args:
          - confidence_threshold: 0.5
            max_detections: 100
```

## Algorithms and Models

ë³¸ ì†”ë£¨ì…˜ì€ **Grounding DINO** ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤. Grounding DINOëŠ” **Transformer ê¸°ë°˜ì˜ Object Detection ëª¨ë¸**ë¡œ, ìì—°ì–´ ì¿¼ë¦¬ë¥¼ í™œìš©í•œ Zero-Shot íƒì§€ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤. CLIP ê¸°ë°˜ì˜ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ë§¤ì¹­ ê¸°ë²•ì„ ì‚¬ìš©í•˜ì—¬ **ì‚¬ì „ ì •ì˜ë˜ì§€ ì•Šì€ ê°ì²´ë„ íƒì§€**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

# ğŸ“‚ Input and Artifacts

## ë°ì´í„° ì¤€ë¹„

**ì…ë ¥ ë°ì´í„° ìš”êµ¬ì‚¬í•­**
- ì´ë¯¸ì§€ ë°ì´í„° (`.jpg`, `.png` ë“±)
- íƒì§€í•  ê°ì²´ì— ëŒ€í•œ **í…ìŠ¤íŠ¸ ì¿¼ë¦¬** (ì˜ˆ: "red car", "dog running")

**ë°ì´í„° ë””ë ‰í† ë¦¬ êµ¬ì¡° ì˜ˆì‹œ**
```
./solution/sample_data/
    â”œâ”€â”€ train/
    â”‚     â”œâ”€â”€ images/
    â”‚     â”‚     â”œâ”€â”€ img1.jpg
    â”‚     â”‚     â”œâ”€â”€ img2.jpg
    â”œâ”€â”€ test/
    â”‚     â”œâ”€â”€ images/
    â”‚     â”‚     â”œâ”€â”€ img1.jpg
    â”‚     â”‚     â”œâ”€â”€ img2.jpg
```

## ì‚°ì¶œë¬¼ (Artifacts)

**Train pipeline**
```
./alo/train_artifacts/
    â”œâ”€â”€ models/
    â”‚     â”œâ”€â”€ model_best.pth  # í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜
    â”œâ”€â”€ log/
    â”‚     â”œâ”€â”€ training.log  # í•™ìŠµ ê³¼ì • ë¡œê·¸
```

**Inference pipeline**
```
./alo/inference_artifacts/
    â”œâ”€â”€ output/
    â”‚     â”œâ”€â”€ predictions.csv  # íƒì§€ëœ ê°ì²´ ê²°ê³¼
    â”œâ”€â”€ score/
    â”‚     â”œâ”€â”€ inference_summary.yaml  # ì¶”ë¡  ìš”ì•½
```

**predictions.csv**
- íƒì§€ëœ ê°ì²´ ë¦¬ìŠ¤íŠ¸ ë° bounding box ì¢Œí‘œ í¬í•¨
- ì˜ˆì‹œ:
```
image_id,object,confidence,x_min,y_min,x_max,y_max
img1.jpg,car,0.92,30,50,120,200
img2.jpg,person,0.88,60,80,170,250
```

**inference_summary.yaml**
- Zero-Shot íƒì§€ ê²°ê³¼ ìš”ì•½ ì •ë³´ ì œê³µ


<br>
<br>


## :hammer_and_wrench:  Requirements and Install 

Basic Dependencies:

* Python == 3.10
<br>

**Installation:**

<br>
1.Clone the ALO repository from GitHub.

```bash
git clone https://github.com/mellerikat/alo.git zeroshot_od
```

<br>
2. Clone the zeroshot-objectdetection solution repository from GitHub.

```bash
git clone https://github.com/mellerihub/zeroshot-objectdetection.git
```

<br>
3. Download pre=trained tokenizer adn model weights.

```bash
cd assets
cd inference
git clone git@hf.co:google-bert/bert-base-uncased

cd groundingdino
cd checkpoints
wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth
```

<br>
4. Install the required dependencies in the solution directory.

```bash
pip install -r requirements.txt
cd assets
cd inference
pip install -e .
```

<br>
5. Local Demo start

```bash
python main.py
```
